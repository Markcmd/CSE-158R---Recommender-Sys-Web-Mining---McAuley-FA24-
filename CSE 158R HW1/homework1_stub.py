# -*- coding: utf-8 -*-
"""Homework1_stub.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Markcmd/CSE-158R---Recommender-Sys-Web-Mining---McAuley-FA24-/blob/main/CSE%20158R%20HW1/Homework1_stub.ipynb
"""

import json
from matplotlib import pyplot as plt
from collections import defaultdict
from sklearn import linear_model
import numpy
import random
import gzip
import math

import warnings
warnings.filterwarnings("ignore")

def assertFloat(x): # Checks that an answer is a float
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N

f = gzip.open("young_adult_10000.json.gz")
dataset = []
for l in f:
    dataset.append(json.loads(l))

len(dataset)

answers = {} # Put your answers to each question in this dictionary

dataset[0]

"""# Question 1"""

# Vectors of the features,
#  -- count of the "!" character.
def feature(datum):
  # review_text from datum
  text = datum['review_text']

  # count "!"
  count = text.count('!')

  # return feature vector with first column is 1
  return [1, count]

# Matrix of the features
X = numpy.array([feature(datum = data) for data in dataset])

# Vector of the outputs
Y = numpy.array([data['rating'] for data in dataset])

"""$$
\theta = (X^T X)^{-1} X^T y
$$


"""

# Calculate Thetas, with Psuedo Inverse of X. shape (,2)
theta = numpy.linalg.inv(X.T @ X) @ X.T @ Y

"""$$\text{MSE}: \frac{1}{N} \sum_{i=1}^{N} \left( X_i \cdot \theta - y_i \right)^2$$, $$X\theta = y$$


"""

# Calculate MSE
mse = ((Y - X @ theta) ** 2).mean()

answers['Q1'] = [theta[0], theta[1], mse]
print(answers)

assertFloatList(answers['Q1'], 3) # Check the format of your answer (three floats)

"""# Question 2"""

# Vectors of the features,
#  -- text length
#  -- count of the "!" character.
def feature(datum):
  # review_text from datum
  text = datum['review_text']

  #get text length
  length = len(text)

  # count "!"
  count = text.count('!')

  # return feature vector with first columns are [1, length, count]
  return [1, length, count]

# Matrix of Feature
X = numpy.array([feature(datum = data) for data in dataset])

# Vector of Outputs
Y = numpy.array([data['rating'] for data in dataset])

# calculate thetas shape (,3)
theta = numpy.linalg.inv(X.T @ X) @ X.T @ Y

# calculate MSE
mse = ((Y - X @ theta) ** 2).mean()

answers['Q2'] = [theta[0], theta[1], theta[2], mse]

assertFloatList(answers['Q2'], 4)

"""# Question 3"""

# Vectors of the features
# feature for a specific polynomial degree
def feature(datum, deg):
  # review_text from datum
  text = datum['review_text']

  # count "!"
  count = text.count('!')

  # initialize vector
  vector = [1]

  # append degrees
  for i in range(1, deg + 1):
    vector.append(count ** i)

  return vector

mses = []

# Fit polynomials from degree one to five
degrees = 5
for degree in range(1, degrees+1):
  # Matrix of Feature
  X = numpy.array([feature(datum = data,deg = degree) for data in dataset])

  # Vector of Outputs
  Y = numpy.array([data['rating'] for data in dataset])

  # calculate thetas shape (,degree+1)
  theta = numpy.linalg.inv(X.T @ X) @ X.T @ Y

  # calculate MSE
  mse = ((Y - X @ theta) ** 2).mean()

  # append
  mses.append(mse)

answers['Q3'] = mses

assertFloatList(answers['Q3'], 5)# List of length 5

"""# Questions 4

This question need functions in the questions 3
"""

# split dataset into training and test withe 1:1 ratio
random.shuffle(dataset)
dataset_train = dataset[:len(dataset)//2]
dataset_test = dataset[len(dataset)//2:]

mses_test = []

# Fit polynomials from degree one to five
# train with dataset_train, output mse of dataset_test
degrees = 5
for degree in range(1, degrees+1):
  # Matrix of Feature
  X_train = numpy.array([feature(datum = data,deg = degree) for data in dataset_train])
  X_test = numpy.array([feature(datum = data,deg = degree) for data in dataset_test])

  # Vector of Outputs
  Y_train = numpy.array([data['rating'] for data in dataset_train])
  Y_test = numpy.array([data['rating'] for data in dataset_test])

  # calculate thetas shape (,degree+1) (or Fit)
  theta = numpy.linalg.inv(X_train.T @ X_train) @ X_train.T @ Y_train

  # calculate MSE for test set
  mse_test = ((Y_test - X_test @ theta) ** 2).mean()

  # append
  mses_test.append(mse_test)

answers['Q4'] = mses_test
answers['Q4']

assertFloatList(answers['Q4'], 5)

"""# Question 5"""

# Vectors of the features
# trivial
def feature_trivial():
  # initialize vector
  vector = [1]

  return vector

# Matrix of feature
X = numpy.array([feature_trivial() for data in dataset])

# Vector of outputs
Y = numpy.array([data['rating'] for data in dataset])

# calculate theta
theta = numpy.linalg.inv(X.T @ X) @ X.T @ Y

# calculate mae
mae = abs(Y - X @ theta).mean()

answers['Q5'] = mae

assertFloat(answers['Q5'])

"""# Question 6"""

f = open("beer_50000.json")
dataset = []
for l in f:
    if 'user/gender' in l:
        dataset.append(eval(l))

len(dataset)

dataset[0]

# vector of features
def feature(datum):
  # review_text from datum
  text = datum['review/text']

  # count "!"
  count = text.count('!')

  # return feature vector with first column is 1
  return [1, count]

# Matrix of features
X = numpy.array([feature(datum = data) for data in dataset])

# Vector of ouputs, use binary encoding but use numerical value 0 and 1, femal 0 male 1
Y = numpy.array([(1 if data['user/gender'] == 'Female' else 0) for data in dataset])

# Fit a logistic regressor
# use a logistic regression library with default parameters, e.g. linear model.LogisticRegression() from sklearn
model = linear_model.LogisticRegression()
model.fit(X,Y)

"""$$\text{Balanced Error Rate (BER)} = \frac{1}{2} (\text{FPR} + \text{FNR})
$$
"""

# calculate TP
TP = ((Y ==1) & (model.predict(X) == 1)).sum()

# calculate TN
TN = ((Y ==0) & (model.predict(X) == 0)).sum()

# calculate FP
FP = ((Y ==0) & (model.predict(X) == 1)).sum()

# calculate FN
FN = ((Y ==1) & (model.predict(X) == 0)).sum()

# calculate FPR
FPR = FP / (FP + TN)

# calculate FNR
FNR = FN / (FN + TP)

# calculate BER
BER = 0.5 * (FPR + FNR)

# convert these value to standard Python types
TP = float(TP)
TN = float(TN)
FP = float(FP)
FN = float(FN)
BER = float(BER)

answers['Q6'] = [TP, TN, FP, FN, BER]

assertFloatList(answers['Q6'], 5)

print(answers)

"""# Question 7"""

# Fit a logistic regressor
# use a logistic regression library with default parameters, e.g. linear model.LogisticRegression() from sklearn
model = linear_model.LogisticRegression(class_weight = 'balanced')
model.fit(X,Y)

# calculate TP
TP = ((Y ==1) & (model.predict(X) == 1)).sum()

# calculate TN
TN = ((Y ==0) & (model.predict(X) == 0)).sum()

# calculate FP
FP = ((Y ==0) & (model.predict(X) == 1)).sum()

# calculate FN
FN = ((Y ==1) & (model.predict(X) == 0)).sum()

# calculate FPR
FPR = FP / (FP + TN)

# calculate FNR
FNR = FN / (FN + TP)

# calculate BER
BER = 0.5 * (FPR + FNR)

# convert these value to standard Python types
TP = float(TP)
TN = float(TN)
FP = float(FP)
FN = float(FN)
BER = float(BER)

answers["Q7"] = [TP, TN, FP, FN, BER]

assertFloatList(answers['Q7'], 5)

"""# Question 8"""

# calculate scores
scores = model.decision_function(X)
len(scores)

# concate scores and Y
scores_Y = list(zip(scores, Y))

"""Note: highest score most confident"""

# Sort scores_Y decsenting order
sorted_scores_Y = sorted(scores_Y, key = lambda x: x[0], reverse = True)
sorted_scores_Y[:10]

precisionList = []

ks = [1, 10, 100, 1000, 10000]

# Calculate precisions @ ks
for k in ks:
  TP = 0
  for i in range(k):
    if sorted_scores_Y[i][0] > 0 and (sorted_scores_Y[i][1] == 1):
      TP += 1
  precision = TP / k
  precisionList.append(precision)

answers['Q8'] = precisionList

assertFloatList(answers['Q8'], 5) #List of five floats

"""# Write Answer to File

"""

f = open("answers_hw1.txt", 'w') # Write your answers to a file
f.write(str(answers) + '\n')
f.close()

